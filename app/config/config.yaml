# Enhanced RAG Configuration with Integrated Improvements
app:
  name: "Enhanced RAG Chatbot"
  version: "3.0.0"
  debug: false

server:
  host: "${HOST:-0.0.0.0}"
  port: "${PORT:-8000}"

qdrant:
  url: "${QDRANT_URL}"
  api_key: "${QDRANT_API_KEY:-}"
  collection_name: "${QDRANT_COLLECTION_NAME:-junggu_agent}"
  vector_size: 1536  # gemini-embedding-001의 1536 차원에 맞춤
  distance: "cosine"
  hybrid_search:
    dense_weight: 0.6
    sparse_weight: 0.4

embeddings:
  provider: "google"  # google로 통일
  model: "models/gemini-embedding-001"  # 올바른 모델명 형식
  output_dimensionality: 1536  # gemini-embedding-001의 실제 차원 수
  task_type: "RETRIEVAL_DOCUMENT"  # RAG 문서 검색용 최적화
  sparse_model: "Qdrant/bm42-all-minilm-l6-v2-attentions"
  batch_size: 100

sparse_embeddings:
  enabled: true
  model: "Qdrant/bm42-all-minilm-l6-v2-attentions"
  cache_dir: "models/sparse"

llm:
  providers: ["google", "anthropic", "openai"]
  default_provider: "openai"  # 기본 모델 설정 (google, anthropic, openai 중 선택)
  auto_fallback: true  # 자동 폴백 활성화
  fallback_order: ["openai", "anthropic", "google"]  # 폴백 순서 설정
  google:
    model: "gemini-2.0-flash-exp"
    api_key: "${GOOGLE_API_KEY:-}"
    temperature: 0.3
    max_tokens: 10000
  anthropic:
    model: "claude-sonnet-4-20250514"
    api_key: "${ANTHROPIC_API_KEY:-}"
    temperature: 0.3
    max_tokens: 10000
  openai:
    model: "gpt-5-2025-08-07"
    api_key: "${OPENAI_API_KEY:-}"
    temperature: 0.3
    max_tokens: 10000

# 강화된 문서 처리 설정 
document_processing:
  # 시멘틱 청킹 설정 (새로 추가)
  splitter_type: "semantic"  # recursive, semantic, hybrid 중 선택
  target_chunk_size: 1250     # 목표 청크 크기 (1,000-1,500자 중간값)
  min_chunk_size: 1000        # 최소 청크 크기  
  max_chunk_size: 1500        # 최대 청크 크기
  
  # 시멘틱 분할 고급 설정
  semantic_threshold: 0.3     # 의미적 분할 임계값 (0.0-1.0)
  overlap_sentences: 2        # 오버랩할 문장 수
  sentence_window: 3          # 의미 분석 윈도우 크기
  preserve_structure: true    # 문서 구조 보존 여부
  korean_optimized: true      # 한국어 최적화 활성화
  
  # 기존 설정 (호환성 유지)
  chunk_size: 1250           # semantic chunking 사용 시 target_chunk_size와 동일
  chunk_overlap: 100         # semantic chunking 사용 시 자동 계산
  max_file_size: 52428800    # 50MB

# 강화된 검색 설정
retrieval:
  max_sources: 25
  min_score: 0.15            # 기본 임계값 (동적 임계값 비활성화 시)
  top_k: 10

# 다중 쿼리 확장 설정 (Multi-Query Expansion)
multi_query:
  enable_query_expansion: true     # 쿼리 확장 활성화 여부
  expansion_model: "gpt-5-nano"    # 확장에 사용할 모델
  max_expanded_queries: 3          # 최대 추가 쿼리 수
  fusion_strategy: "rrf"           # 결과 융합 전략 (rrf, weighted_avg, max_score)
  diversity_bonus: 0.05           # 쿼리 다양성 보너스 점수
  enable_reranking: true
  quality_threshold: 0.15
  deduplication_enabled: true
  
  # 동적 임계값 설정 (새로 추가)
  enable_dynamic_threshold: true
  dynamic_threshold:
    base_threshold: 0.15      # 시작 임계값
    target_min_results: 5     # 목표 최소 결과 수
    threshold_levels: [0.15, 0.10, 0.05, 0.01]  # 임계값 단계
    learning_enabled: true    # 학습 기반 최적화
    cache_enabled: true       # 캐싱 활성화
    cache_ttl: 1800          # 캐시 TTL (30분)
  
  # GPT-5 쿼리 확장 설정 (새로 추가)  
  enable_query_expansion: true
  query_expansion:
    model: "gpt-5-nano"       # GPT-5 nano 모델 사용
    temperature: 0.3          # 창의성 조절
    max_tokens: 1000          # 최대 토큰 수
    cache_ttl: 3600          # 캐시 TTL (1시간)
    min_query_length: 10      # 확장 대상 최소 쿼리 길이
    max_synonyms: 5           # 최대 동의어 수
    expansion_strategies:     # 확장 전략
      - "synonym"             # 동의어 확장
      - "intent"              # 의도 분석
      - "keyword"             # 핵심 키워드 추출
    fallback_enabled: true    # 실패 시 원본 쿼리 사용

reranking:
  enabled: true
  default_provider: "llm"  # API 키 없이 LLM 리랭킹 사용
  min_score: 0.15  # 리랭킹 후 최소 점수 15%
  providers:
    cohere:
      api_key: ""  # 필요시 API 키 추가
      model: "rerank-multilingual-v2.0"
    jina:
      api_key: ""  # 필요시 API 키 추가
      model: "jina-reranker-v1-base-en"
      endpoint: "https://api.jina.ai/v1/rerank"
    llm:
      enabled: true  # LLM 기반 리랭킹 활성화
      provider: "openai"  # OpenAI GPT-5-nano 사용
      model: "gpt-5-nano"  # 고속 분류/순위 작업 최적화
      max_tokens: 800

session:
  ttl: 7200  # 2시간으로 연장 (기존 1시간 → 2시간)
  max_exchanges: 10  # 최대 교환 수도 증가 (5 → 10)
  max_conversation_memory: 10  # 기억할 최근 대화 수
  use_langchain_memory: true  # LangChain 메모리 사용
  memory_type: "buffer"  # buffer, window, summary 중 선택

logging:
  level: "DEBUG"
  format: "structured"

uploads:
  directory: "./uploads"
  max_file_size: 52428800
  allowed_types: [".pdf", ".txt", ".md", ".docx", ".xlsx", ".json"]

# 시스템 모니터링 설정 (새로 추가)
monitoring:
  enable_stats_tracking: true
  stats_reset_interval: 86400  # 24시간
  performance_logging: true
  component_health_checks: true
