"""
Chat API endpoints
ì±„íŒ… ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸
"""
import time
from datetime import datetime
from typing import Dict, Any, Optional, List
from uuid import uuid4

from fastapi import APIRouter, HTTPException, Request, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field, validator
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

from ..lib.logger import get_logger, create_chat_logging_middleware

logger = get_logger(__name__)
chat_logger = create_chat_logging_middleware()
router = APIRouter()

# Dependencies (will be injected from main.py)
modules: Dict[str, Any] = {}
config: Dict[str, Any] = {}

def set_dependencies(app_modules: Dict[str, Any], app_config: Dict[str, Any]):
    """ì˜ì¡´ì„± ì£¼ì…"""
    global modules, config
    modules = app_modules
    config = app_config

# Rate limiter
limiter = Limiter(key_func=get_remote_address)

class ChatRequest(BaseModel):
    """ì±„íŒ… ìš”ì²­ ëª¨ë¸"""
    message: str = Field(..., min_length=1, max_length=1000, description="ì‚¬ìš©ì ë©”ì‹œì§€")
    session_id: Optional[str] = Field(None, description="ì„¸ì…˜ ID")
    stream: bool = Field(False, description="ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì—¬ë¶€")
    options: Optional[Dict[str, Any]] = Field(default_factory=dict, description="ì¶”ê°€ ì˜µì…˜")

    @validator('message')
    def validate_message(cls, v):
        if not v or not v.strip():
            raise ValueError("Message cannot be empty")
        return v.strip()

class Source(BaseModel):
    """ì†ŒìŠ¤ ì •ë³´ ëª¨ë¸"""
    id: int
    document: str
    page: Optional[int] = None
    chunk: Optional[int] = None
    relevance: float
    content_preview: str

class ChatResponse(BaseModel):
    """ì±„íŒ… ì‘ë‹µ ëª¨ë¸"""
    answer: str
    sources: List[Source]
    session_id: str
    processing_time: float
    tokens_used: int
    timestamp: str
    model_info: Optional[Dict[str, Any]] = None

class SessionCreateRequest(BaseModel):
    """ì„¸ì…˜ ìƒì„± ìš”ì²­ ëª¨ë¸"""
    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict)

class SessionResponse(BaseModel):
    """ì„¸ì…˜ ì‘ë‹µ ëª¨ë¸"""
    session_id: str
    message: str
    timestamp: str

class ChatHistoryResponse(BaseModel):
    """ì±„íŒ… íˆìŠ¤í† ë¦¬ ì‘ë‹µ ëª¨ë¸"""
    session_id: str
    messages: List[Dict[str, Any]]
    total_messages: int
    limit: int
    offset: int
    has_more: bool

class StatsResponse(BaseModel):
    """í†µê³„ ì‘ë‹µ ëª¨ë¸"""
    chat: Dict[str, Any]
    session: Dict[str, Any]
    timestamp: str

# í†µê³„ ì •ë³´
stats = {
    "total_chats": 0,
    "total_tokens": 0,
    "average_latency": 0.0,
    "error_rate": 0.0,
    "errors": 0
}

def update_stats(data: Dict[str, Any]):
    """í†µê³„ ì—…ë°ì´íŠ¸"""
    stats["total_chats"] += 1
    
    if data.get("success"):
        if data.get("tokens_used"):
            stats["total_tokens"] += data["tokens_used"]
            
        if data.get("latency"):
            current_avg = stats["average_latency"]
            chat_count = stats["total_chats"]
            stats["average_latency"] = (current_avg * (chat_count - 1) + data["latency"]) / chat_count
    else:
        stats["errors"] += 1
        stats["error_rate"] = (stats["errors"] / stats["total_chats"]) * 100

def get_request_context(request: Request) -> Dict[str, Any]:
    """ìš”ì²­ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    return {
        "ip_address": request.client.host if request.client else None,
        "user_agent": request.headers.get("user-agent"),
        "referrer": request.headers.get("referer")
    }

async def handle_session(session_id: Optional[str], context: Dict[str, Any]) -> Dict[str, Any]:
    """ì„¸ì…˜ ì²˜ë¦¬ - ê°œì„ ëœ ë²„ì „ (ì„¸ì…˜ ID ë¶ˆì¼ì¹˜ ë°©ì§€ ê°•í™”)"""
    try:
        session_module = modules.get('session')
        if not session_module:
            raise HTTPException(status_code=500, detail="Session module not available")
        
        # ìš”ì²­ëœ session_id ë¡œê¹… (ë””ë²„ê¹…ìš©)
        logger.info(f"ğŸ” ì„¸ì…˜ ìš”ì²­ - ìš”ì²­ë°›ì€ session_id: {session_id}")
            
        if session_id:
            # ê¸°ì¡´ ì„¸ì…˜ ì¡°íšŒ
            logger.info(f"ê¸°ì¡´ ì„¸ì…˜ ì¡°íšŒ ì‹œë„: {session_id}")
            logger.debug(f"ì„¸ì…˜ ëª¨ë“ˆì˜ í˜„ì¬ ì„¸ì…˜ë“¤: {list(session_module.sessions.keys())}")
            session_result = await session_module.get_session(session_id, context)
            
            if session_result.get("is_valid"):
                # ì¤‘ìš”: ì›ë˜ ìš”ì²­ëœ session_idë¥¼ ë°˜ë“œì‹œ ìœ ì§€!
                logger.info(f"âœ… ì„¸ì…˜ ìœ íš¨í•¨ - ìš”ì²­ ID: {session_id}, ì‘ë‹µ ID: {session_id}")
                
                # ë°©ì–´ì  ê²€ì¦: ìš”ì²­ê³¼ ì‘ë‹µ IDê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                result_session_id = session_result.get('renewed_session_id', session_id)
                if result_session_id != session_id:
                    logger.error(f"ğŸš¨ ì„¸ì…˜ ID ë¶ˆì¼ì¹˜ ê°ì§€! ìš”ì²­: {session_id}, ì‘ë‹µ: {result_session_id}")
                
                return {
                    "success": True,
                    "session_id": session_id,  # ë¬´ì¡°ê±´ ì›ë³¸ session_id ì‚¬ìš©
                    "is_new": False,
                    "validation_result": session_result
                }
            else:
                logger.warning(f"ì„¸ì…˜ ë§Œë£Œ/ì—†ìŒ: {session_id}, ì´ìœ : {session_result.get('reason', 'unknown')}")
                # ì„¸ì…˜ì´ ë§Œë£Œë˜ê±°ë‚˜ ì—†ì„ ë•Œ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
                logger.info(f"ìƒˆ ì„¸ì…˜ ìƒì„± ì¤‘... (ê¸°ì¡´ ì„¸ì…˜: {session_id})")
        
        # ìƒˆ ì„¸ì…˜ ìƒì„± - ì‚¬ìš©ì ì œê³µ ì„¸ì…˜ ID ì‚¬ìš©
        logger.debug(f"ìƒˆ ì„¸ì…˜ ìƒì„± ì „ - ì„¸ì…˜ ëª¨ë“ˆ ID: {id(session_module)}")
        new_session = await session_module.create_session({"metadata": context}, session_id=session_id)
        new_session_id = new_session["session_id"]
        
        logger.info(f"âœ… ìƒˆ ì„¸ì…˜ ìƒì„± ì™„ë£Œ - ìƒì„±ëœ session_id: {new_session_id}")
        logger.debug(f"ìƒˆ ì„¸ì…˜ ìƒì„± í›„ - ì „ì²´ ì„¸ì…˜ ìˆ˜: {len(session_module.sessions)}")
        logger.debug(f"ìƒˆ ì„¸ì…˜ ìƒì„± í›„ - ì„¸ì…˜ í‚¤ ëª©ë¡: {list(session_module.sessions.keys())}")
        
        return {
            "success": True,
            "session_id": new_session_id,
            "is_new": True,
            "message": "ìƒˆ ëŒ€í™” ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        
    except Exception as e:
        logger.error(f"Session handling error: {e}")
        return {
            "success": False,
            "message": "Failed to handle session"
        }

def extract_topic(message: str) -> str:
    """í† í”½ ì¶”ì¶œ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)"""
    # ì•ˆì „í•œ ë©”ì‹œì§€ ì²˜ë¦¬
    if isinstance(message, list):
        message = ' '.join(str(item) for item in message)
    elif not isinstance(message, str):
        message = str(message)
    
    if not message:
        return 'general'
    
    keywords = {
        'search': ['ê²€ìƒ‰', 'ì°¾ê¸°', 'ì°¾ì•„', 'ê²€ìƒ‰í•´'],
        'document': ['ë¬¸ì„œ', 'íŒŒì¼', 'ìë£Œ', 'ë°ì´í„°'],
        'help': ['ë„ì›€', 'ë„ì™€', 'ì„¤ëª…', 'ì•Œë ¤'],
        'technical': ['ê¸°ìˆ ', 'ê°œë°œ', 'ì½”ë“œ', 'í”„ë¡œê·¸ë˜ë°'],
        'general': ['ì¼ë°˜', 'ê¸°ë³¸', 'ì†Œê°œ', 'ê°œìš”']
    }
    
    try:
        lower_message = message.lower()
        
        for topic, words in keywords.items():
            if any(word in lower_message for word in words):
                return topic
        
        return 'general'
    except Exception:
        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return 'general'

async def execute_rag_pipeline(message: str, session_id: str, options: Dict[str, Any] = None) -> Dict[str, Any]:
    """RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    start_time = time.time()
    options = options or {}
    
    logger.info("RAG Pipeline Starting", 
               message_preview=message[:50],
               session_id=session_id,
               has_retrieval_module=bool(modules.get('retrieval')),
               has_generation_module=bool(modules.get('generation')))
    
    try:
        session_module = modules.get('session')
        retrieval_module = modules.get('retrieval')
        generation_module = modules.get('generation')
        
        if not all([session_module, retrieval_module, generation_module]):
            raise Exception("Required modules not available")
        
        # 1. ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ - ë””ë²„ê¹… ì¶”ê°€
        logger.debug("Step 1: Getting session context...")
        
        # ì„¸ì…˜ ìƒíƒœ ë””ë²„ê¹…
        logger.debug(f"ì„¸ì…˜ ëª¨ë“ˆ ID: {id(session_module)}")
        logger.debug(f"ì „ì²´ ì„¸ì…˜ ìˆ˜: {len(session_module.sessions)}")
        logger.debug(f"ì„¸ì…˜ í‚¤ ëª©ë¡: {list(session_module.sessions.keys())}")
        logger.debug(f"ìš”ì²­ëœ ì„¸ì…˜ ID: {session_id}")
        
        context_string = await session_module.get_context_string(session_id)
        logger.debug("Session context retrieved", has_context=bool(context_string))
        
        # 2. ê²€ìƒ‰ ì‹¤í–‰
        logger.debug("Step 2: Starting document retrieval...")
        try:
            retrieval_config = config.get("retrieval", {})
            search_results = await retrieval_module.search(message, {
                "limit": options.get("max_sources", retrieval_config.get("max_sources", 20)),
                "min_score": options.get("min_score", retrieval_config.get("min_score", 0.01)),
                "context_string": context_string
            })
            logger.debug("Document retrieval completed", result_count=len(search_results))
        except Exception as search_error:
            search_error.step = "document_retrieval"
            raise search_error
        
        # 3. ë¦¬ë­í‚¹ ì‹¤í–‰ (ì„¤ì •ëœ ê²½ìš°)
        ranked_results = search_results
        if retrieval_config.get("enable_reranking", False) and search_results:
            logger.debug("Starting reranking...")
            try:
                ranked_results = await retrieval_module.rerank(message, search_results, {
                    "top_k": options.get("top_k", 10),  # ë¦¬ë­í‚¹ í›„ 10ê°œë¡œ ë³€ê²½
                    "min_score": options.get("min_score", 0.15)  # 15% ì´í•˜ í•„í„°ë§
                })
                logger.debug("Reranking completed successfully",
                           original_count=len(search_results),
                           reranked_count=len(ranked_results))
            except Exception as reranker_error:
                logger.warning("Reranking failed, using original search results",
                             error=str(reranker_error))
                ranked_results = search_results
        else:
            logger.debug("Reranking disabled, using search results directly",
                        enabled=retrieval_config.get("enable_reranking", False),
                        result_count=len(search_results))
        
        # 4. ë‹µë³€ ìƒì„±
        logger.debug("Step 4: Starting answer generation...",
                    context_count=len(ranked_results),
                    has_session_context=bool(context_string))
        
        try:
            generation_result = await generation_module.generate_answer(message, ranked_results, {
                "session_context": context_string,
                "style": options.get("response_style", "standard"),
                "max_tokens": options.get("max_tokens", 2000)
            })
            
            # ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            answer_text = getattr(generation_result, 'answer', '') or getattr(generation_result, 'text', '')
            if isinstance(answer_text, list):
                answer_text = ' '.join(str(item) for item in answer_text)
            
            logger.info("Answer generation completed",
                       result_type=type(generation_result).__name__,
                       has_result=bool(generation_result),
                       has_text=bool(answer_text),
                       tokens_used=getattr(generation_result, 'tokens_used', 0))
                       
        except Exception as generation_error:
            logger.error("Answer generation error", error=str(generation_error))
            generation_error.step = "answer_generation"
            raise generation_error
        
        # 5. ê²°ê³¼ í¬ë§·íŒ…
        logger.debug("Step 5: Starting result formatting...")
        sources = []
        try:
            # ìµœëŒ€ 10ê°œê¹Œì§€ í‘œì‹œí•˜ë˜, 15% ì´ìƒì¸ ë¬¸ì„œë§Œ í¬í•¨
            for index, doc in enumerate(ranked_results[:options.get("max_sources", 10)]):
                try:
                    # ë©”íƒ€ë°ì´í„° êµ¬ì¡° ë¶„ì„
                    if index == 0:
                        # ì•ˆì „í•œ keys ì¶”ì¶œ
                        doc_keys = None
                        try:
                            if hasattr(doc, 'keys'):
                                # doc.keys()ê°€ ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                                keys_obj = doc.keys()
                                if isinstance(keys_obj, list):
                                    doc_keys = keys_obj
                                else:
                                    doc_keys = list(keys_obj)
                        except Exception as keys_error:
                            logger.debug(f"Could not extract keys from document: {keys_error}")
                            doc_keys = None
                        
                        logger.info("Document metadata structure analysis",
                                   doc_type=type(doc).__name__,
                                   doc_keys=doc_keys)
                    
                    # ë‹¤ì–‘í•œ ë©”íƒ€ë°ì´í„° ìœ„ì¹˜ì—ì„œ ì •ë³´ ì¶”ì¶œ
                    original_doc = getattr(doc, '_original', doc)
                    metadata = {}
                    
                    if hasattr(original_doc, 'payload') and original_doc.payload:
                        metadata = getattr(original_doc.payload, 'metadata', {})
                    elif hasattr(original_doc, 'metadata'):
                        metadata = original_doc.metadata
                    elif hasattr(doc, 'metadata'):
                        metadata = doc.metadata
                    
                    # ìœ ì‚¬ë„ ì ìˆ˜ ê°€ì ¸ì˜¤ê¸° (0~1 ë²”ìœ„)
                    raw_score = getattr(doc, 'score', 0)
                    
                    # 15% ë¯¸ë§Œ ë¬¸ì„œëŠ” ì œì™¸
                    if raw_score < 0.15:
                        continue
                    
                    # ì½˜í…ì¸  ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•˜ì—¬ ë¬¸ìì—´ë¡œ ë³€í™˜
                    doc_content = getattr(doc, 'content', '') or ''
                    if isinstance(doc_content, list):
                        logger.debug(f"Document {index} content is list type, converting to string")
                        doc_content = ' '.join(str(item) for item in doc_content)
                    elif not isinstance(doc_content, str):
                        logger.debug(f"Document {index} content type: {type(doc_content)}, converting to string")
                        doc_content = str(doc_content)
                    
                    logger.debug(f"Processing document {index} - score: {raw_score}, content length: {len(doc_content)}")
                    
                    sources.append(Source(
                        id=index + 1,
                        document=metadata.get('source_file') or metadata.get('source') or 
                                metadata.get('filename') or metadata.get('document_id') or 'Unknown',
                        page=metadata.get('page_number') or metadata.get('page'),
                        chunk=metadata.get('chunk_index') or metadata.get('chunk'),
                        relevance=raw_score,  # ì •ê·œí™”ëœ ì ìˆ˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        content_preview=doc_content[:150] + '...' if doc_content else 'No content'
                    ))
                except Exception as doc_error:
                    logger.error(f"Error processing document {index}: {doc_error}")
                    continue
        except Exception as sources_error:
            logger.error(f"Error in sources processing: {sources_error}")
            sources = []
        
        # ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ë‹µë³€ ì¶”ì¶œ
        logger.debug("Step 6: Extracting final answer...")
        try:
            logger.debug(f"Generation result type: {type(generation_result)}")
            
            # ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ì†ì„± í™•ì¸
            try:
                attrs = dir(generation_result)
                logger.debug(f"Generation result attributes: {attrs}")
            except Exception as attr_error:
                logger.debug(f"Could not get attributes: {attr_error}")
            
            final_answer = getattr(generation_result, 'answer', '') or getattr(generation_result, 'text', '')
            logger.debug(f"Final answer type: {type(final_answer)}")
            
            if isinstance(final_answer, list):
                logger.debug("Final answer is list type, converting to string")
                final_answer = ' '.join(str(item) for item in final_answer)
            
            logger.debug(f"Final answer length: {len(final_answer) if final_answer else 0}")
            
            # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ìƒì„±
            logger.debug("Step 7: Creating result dictionary...")
            # ì•ˆì „í•œ ê¸¸ì´ ê³„ì‚°
            search_count = len(search_results) if search_results else 0
            ranked_count = len(ranked_results) if ranked_results else 0
            
            result_dict = {
                "answer": final_answer,
                "sources": sources,
                "tokens_used": getattr(generation_result, 'tokens_used', 0),
                "topic": extract_topic(message),
                "processing_time": time.time() - start_time,
                "search_results": search_count,
                "ranked_results": ranked_count,
                "model_info": {
                    "provider": getattr(generation_result, 'provider', 'unknown'),
                    "model": getattr(generation_result, 'model_used', 'unknown'),
                    "generation_time": getattr(generation_result, 'generation_time', 0),
                    "model_config": getattr(generation_result, 'model_config', {})
                }
            }
            logger.debug("Result dictionary created successfully")
            return result_dict
            
        except Exception as final_error:
            logger.error(f"Error in final answer processing: {final_error}")
            raise final_error
        
    except Exception as error:
        logger.error("RAG pipeline error",
                    error=str(error),
                    step=getattr(error, 'step', 'unknown'),
                    processing_time=time.time() - start_time)
        
        # í´ë°± ì‘ë‹µ
        return {
            "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
            "sources": [],
            "tokens_used": 0,
            "topic": extract_topic(message),
            "processing_time": time.time() - start_time,
            "search_results": 0,
            "ranked_results": 0,
            "error": True,
            "error_message": str(error)
        }

@router.post("/chat", response_model=ChatResponse)
@limiter.limit("100/15minutes")
async def chat(request: Request, chat_request: ChatRequest):
    """ì±„íŒ… ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸"""
    start_time = time.time()
    session_id = None
    
    try:
        # 1. ì„¸ì…˜ ì²˜ë¦¬
        context = get_request_context(request)
        session_result = await handle_session(chat_request.session_id, context)
        
        if not session_result["success"]:
            raise HTTPException(status_code=400, detail=session_result.get("message", "Session error"))
        
        session_id = session_result["session_id"]
        
        # 2. RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        rag_result = await execute_rag_pipeline(chat_request.message, session_id, chat_request.options)
        
        # 3. ì„¸ì…˜ì— ëŒ€í™” ê¸°ë¡
        session_module = modules.get('session')
        if session_module:
            logger.debug(f"ëŒ€í™” ì¶”ê°€ ì „ - ì„¸ì…˜ ëª¨ë“ˆ ID: {id(session_module)}")
            logger.debug(f"ëŒ€í™” ì¶”ê°€ ì „ - ì „ì²´ ì„¸ì…˜ ìˆ˜: {len(session_module.sessions)}")
            logger.debug(f"ëŒ€í™” ì¶”ê°€ ì „ - ì„¸ì…˜ í‚¤ ëª©ë¡: {list(session_module.sessions.keys())}")
            logger.debug(f"ëŒ€í™” ì¶”ê°€í•  ì„¸ì…˜ ID: {session_id}")
            
            await session_module.add_conversation(
                session_id,
                chat_request.message,
                rag_result["answer"],
                {
                    "tokens_used": rag_result["tokens_used"],
                    "response_time": time.time() - start_time,
                    "sources": rag_result["sources"],
                    "topic": rag_result["topic"]
                }
            )
        
        # 4. ì‘ë‹µ ìƒì„±
        response = ChatResponse(
            answer=rag_result["answer"],
            sources=rag_result["sources"],
            session_id=session_id,
            processing_time=time.time() - start_time,
            tokens_used=rag_result["tokens_used"],
            timestamp=datetime.now().isoformat(),
            model_info=rag_result.get("model_info")
        )
        
        # 5. í†µê³„ ì—…ë°ì´íŠ¸
        update_stats({
            "tokens_used": rag_result["tokens_used"],
            "latency": time.time() - start_time,
            "success": True
        })
        
        # 6. ë¡œê¹… (ì¼ì‹œì ìœ¼ë¡œ ë¹„í™œì„±í™”)
        # await chat_logger.log_chat_request(
        #     chat_request.dict(),
        #     response.dict(),
        #     time.time() - start_time,
        #     session_id
        # )
        
        logger.info("Chat request completed successfully", 
                   session_id=session_id,
                   message_length=len(chat_request.message),
                   processing_time=time.time() - start_time,
                   tokens_used=rag_result["tokens_used"],
                   sources_count=len(rag_result["sources"]))
        
        return response
        
    except HTTPException:
        raise
    except Exception as error:
        logger.error("Chat API error", error=str(error), session_id=session_id)
        
        update_stats({"success": False})
        
        # êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ë¶„ë¥˜ ë° ì‚¬ìš©ì ì¹œí™”ì  ë©”ì‹œì§€ ìƒì„±
        error_message = str(error)
        error_type = "unknown"
        user_message = "ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        if "ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼" in error_message or "timeout" in error_message.lower():
            error_type = "timeout"
            user_message = "AI ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        elif "API" in error_message.upper() or "KEY" in error_message.upper() or "credentials" in error_message.lower():
            error_type = "api_auth"
            user_message = "AI ì„œë¹„ìŠ¤ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
        elif "document" in error_message.lower() or "retrieval" in error_message.lower():
            error_type = "retrieval"
            user_message = "ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”."
        elif "session" in error_message.lower():
            error_type = "session"
            user_message = "ì„¸ì…˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        elif "model" in error_message.lower() or "generation" in error_message.lower():
            error_type = "generation" 
            user_message = "AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        
        # ì—ëŸ¬ ì‘ë‹µì— ì˜¬ë°”ë¥¸ êµ¬ì¡° ë³´ì¥
        error_response = ChatResponse(
            answer=user_message,
            sources=[],
            session_id=session_id or "unknown",  # session_idê°€ Noneì¸ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
            processing_time=time.time() - start_time,
            tokens_used=0,
            timestamp=datetime.now().isoformat(),
            model_info={
                "provider": "error",
                "model": "none",
                "generation_time": 0,
                "model_config": {
                    "error_type": error_type,
                    "error_handled": True
                }
            }
        )
        
        # ë¡œê·¸ì— ìƒì„¸í•œ ì—ëŸ¬ ì •ë³´ ê¸°ë¡
        logger.error("Detailed error info", 
                    error_type=error_type, 
                    session_id=session_id,
                    processing_time=time.time() - start_time,
                    message_length=len(chat_request.message) if chat_request else 0)
        
        return error_response

@router.post("/chat/session", response_model=SessionResponse)
async def create_session(request: Request, session_request: SessionCreateRequest):
    """ìƒˆ ì„¸ì…˜ ìƒì„±"""
    try:
        context = get_request_context(request)
        context.update(session_request.metadata)
        
        session_module = modules.get('session')
        if not session_module:
            raise HTTPException(status_code=500, detail="Session module not available")
        
        new_session = await session_module.create_session({"metadata": context})
        
        logger.info(f"New session created: {new_session['session_id']}")
        
        return SessionResponse(
            session_id=new_session["session_id"],
            message="Session created successfully",
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as error:
        logger.error("Create session error", error=str(error))
        raise HTTPException(status_code=500, detail="Failed to create session")

@router.get("/chat/history/{session_id}", response_model=ChatHistoryResponse)
async def get_chat_history(session_id: str, limit: int = 20, offset: int = 0):
    """ì±„íŒ… íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    try:
        session_module = modules.get('session')
        if not session_module:
            raise HTTPException(status_code=500, detail="Session module not available")
        
        history = await session_module.get_chat_history(session_id)
        
        # í˜ì´ì§€ë„¤ì´ì…˜ ì ìš©
        start = offset
        end = start + limit
        paginated_messages = history["messages"][start:end]
        
        return ChatHistoryResponse(
            session_id=session_id,
            messages=paginated_messages,
            total_messages=history["message_count"],
            limit=limit,
            offset=offset,
            has_more=end < history["message_count"]
        )
        
    except Exception as error:
        logger.error("Get chat history error", error=str(error))
        raise HTTPException(status_code=500, detail="Failed to retrieve chat history")

@router.delete("/chat/session/{session_id}")
async def delete_session(session_id: str):
    """ì„¸ì…˜ ì‚­ì œ"""
    try:
        session_module = modules.get('session')
        if not session_module:
            raise HTTPException(status_code=500, detail="Session module not available")
        
        await session_module.delete_session(session_id)
        
        return {
            "message": "Session deleted successfully",
            "session_id": session_id,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as error:
        logger.error("Delete session error", error=str(error))
        raise HTTPException(status_code=500, detail="Failed to delete session")

@router.get("/chat/stats", response_model=StatsResponse)
async def get_stats():
    """í†µê³„ ì¡°íšŒ"""
    try:
        session_module = modules.get('session')
        session_stats = await session_module.get_stats() if session_module else {}
        
        return StatsResponse(
            chat=stats,
            session=session_stats,
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as error:
        logger.error("Get stats error", error=str(error))
        raise HTTPException(status_code=500, detail="Failed to retrieve statistics")